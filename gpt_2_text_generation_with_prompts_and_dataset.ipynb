{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install GPUtil"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:09:07.143553Z",
          "iopub.execute_input": "2023-10-30T07:09:07.144297Z",
          "iopub.status.idle": "2023-10-30T07:09:45.639743Z",
          "shell.execute_reply.started": "2023-10-30T07:09:07.144267Z",
          "shell.execute_reply": "2023-10-30T07:09:45.638650Z"
        },
        "trusted": true,
        "id": "uyMaiJA-U6L6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from numba import cuda\n",
        "from datasets import load_dataset\n",
        "from GPUtil import showUtilization as gpu_usage\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, TrainingArguments, Trainer, default_data_collator"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:09:45.641486Z",
          "iopub.execute_input": "2023-10-30T07:09:45.641780Z",
          "iopub.status.idle": "2023-10-30T07:09:57.013265Z",
          "shell.execute_reply.started": "2023-10-30T07:09:45.641751Z",
          "shell.execute_reply": "2023-10-30T07:09:57.012399Z"
        },
        "trusted": true,
        "id": "2reIz0D4U6L7",
        "outputId": "b2b7fce3-a17c-4084-ffdd-21344bfec804"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:09:57.014864Z",
          "iopub.execute_input": "2023-10-30T07:09:57.015179Z",
          "iopub.status.idle": "2023-10-30T07:09:59.177761Z",
          "shell.execute_reply.started": "2023-10-30T07:09:57.015146Z",
          "shell.execute_reply": "2023-10-30T07:09:59.176693Z"
        },
        "trusted": true,
        "id": "uda-yty4U6L8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2',\n",
        "                                        pad_token_id=tokenizer.eos_token_id)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:09:59.178865Z",
          "iopub.execute_input": "2023-10-30T07:09:59.179193Z",
          "iopub.status.idle": "2023-10-30T07:10:17.560964Z",
          "shell.execute_reply.started": "2023-10-30T07:09:59.179165Z",
          "shell.execute_reply": "2023-10-30T07:10:17.559948Z"
        },
        "trusted": true,
        "id": "xIoOGX5dU6L9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The max model length is {} for this model\".format(tokenizer.model_max_length))\n",
        "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
        "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:17.563318Z",
          "iopub.execute_input": "2023-10-30T07:10:17.563641Z",
          "iopub.status.idle": "2023-10-30T07:10:17.570288Z",
          "shell.execute_reply.started": "2023-10-30T07:10:17.563614Z",
          "shell.execute_reply": "2023-10-30T07:10:17.569008Z"
        },
        "trusted": true,
        "id": "FRLNsjMeU6L9",
        "outputId": "9c666950-3aa7-492f-b14d-90fe0b429069"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "The max model length is 1024 for this model\nThe beginning of sequence token <|endoftext|> token has the id 50256\nThe end of sequence token <|endoftext|> has the id 50256\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.vocab_size"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:17.572018Z",
          "iopub.execute_input": "2023-10-30T07:10:17.572404Z",
          "iopub.status.idle": "2023-10-30T07:10:17.583802Z",
          "shell.execute_reply.started": "2023-10-30T07:10:17.572370Z",
          "shell.execute_reply": "2023-10-30T07:10:17.582785Z"
        },
        "trusted": true,
        "id": "MwYVXcv_U6L9",
        "outputId": "f2232207-e916-46f8-be38-ebe95d5498ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "50257"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:17.585059Z",
          "iopub.execute_input": "2023-10-30T07:10:17.585446Z",
          "iopub.status.idle": "2023-10-30T07:10:17.593693Z",
          "shell.execute_reply.started": "2023-10-30T07:10:17.585411Z",
          "shell.execute_reply": "2023-10-30T07:10:17.592813Z"
        },
        "trusted": true,
        "id": "0jQ8RpWDU6L9",
        "outputId": "40f80d85-a031-4cda-f8bb-f22c2d4317ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "GPT2Tokenizer(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True)}, clean_up_tokenization_spaces=True)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.all_special_tokens"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:17.595276Z",
          "iopub.execute_input": "2023-10-30T07:10:17.595679Z",
          "iopub.status.idle": "2023-10-30T07:10:17.603524Z",
          "shell.execute_reply.started": "2023-10-30T07:10:17.595648Z",
          "shell.execute_reply": "2023-10-30T07:10:17.602689Z"
        },
        "trusted": true,
        "id": "u4XQyf5XU6L-",
        "outputId": "3633ed89-d080-406a-98ab-a937fb008f02"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['<|endoftext|>']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.eos_token_id"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:17.604563Z",
          "iopub.execute_input": "2023-10-30T07:10:17.604926Z",
          "iopub.status.idle": "2023-10-30T07:10:17.614825Z",
          "shell.execute_reply.started": "2023-10-30T07:10:17.604890Z",
          "shell.execute_reply": "2023-10-30T07:10:17.614000Z"
        },
        "trusted": true,
        "id": "pe12aajnU6L-",
        "outputId": "17294301-9864-43ac-e680-021ed0b4cbee"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "50256"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT-2 does not employ padding. Its default maximum supported sentence length is 1024."
      ],
      "metadata": {
        "id": "CfF67IDlU6L-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.max_model_input_sizes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:17.616067Z",
          "iopub.execute_input": "2023-10-30T07:10:17.616436Z",
          "iopub.status.idle": "2023-10-30T07:10:17.623927Z",
          "shell.execute_reply.started": "2023-10-30T07:10:17.616394Z",
          "shell.execute_reply": "2023-10-30T07:10:17.623060Z"
        },
        "trusted": true,
        "id": "E4mN948OU6L-",
        "outputId": "f54b5c5f-5603-4649-9412-fb313ad7fb5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'gpt2': 1024,\n 'gpt2-medium': 1024,\n 'gpt2-large': 1024,\n 'gpt2-xl': 1024,\n 'distilgpt2': 1024}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'I am an Artificial Intelligence Developer'\n",
        "input_ids  = tokenizer.encode(sentence,\n",
        "                              return_tensors = 'pt')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:17.627111Z",
          "iopub.execute_input": "2023-10-30T07:10:17.627409Z",
          "iopub.status.idle": "2023-10-30T07:10:17.635067Z",
          "shell.execute_reply.started": "2023-10-30T07:10:17.627385Z",
          "shell.execute_reply": "2023-10-30T07:10:17.634315Z"
        },
        "trusted": true,
        "id": "gvHnWCSsU6L-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:17.636307Z",
          "iopub.execute_input": "2023-10-30T07:10:17.637083Z",
          "iopub.status.idle": "2023-10-30T07:10:17.646967Z",
          "shell.execute_reply.started": "2023-10-30T07:10:17.637048Z",
          "shell.execute_reply": "2023-10-30T07:10:17.646110Z"
        },
        "trusted": true,
        "id": "Vuu5K5rkU6L-",
        "outputId": "c93efbf9-b618-4c52-d4e9-f6fe1819fc51"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "tensor([[   40,   716,   281, 35941,  9345, 23836]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(input_ids[0][3])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:17.648213Z",
          "iopub.execute_input": "2023-10-30T07:10:17.648504Z",
          "iopub.status.idle": "2023-10-30T07:10:17.655441Z",
          "shell.execute_reply.started": "2023-10-30T07:10:17.648480Z",
          "shell.execute_reply": "2023-10-30T07:10:17.654486Z"
        },
        "trusted": true,
        "id": "aEXLdfJYU6L-",
        "outputId": "40eea9d6-0dd5-4438-9c40-338e808fcdbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "' Artificial'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "greedy_output = model.generate(input_ids,\n",
        "                               max_length=100,\n",
        "                               no_repeat_ngram_size=2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:17.656500Z",
          "iopub.execute_input": "2023-10-30T07:10:17.656745Z",
          "iopub.status.idle": "2023-10-30T07:10:21.023607Z",
          "shell.execute_reply.started": "2023-10-30T07:10:17.656723Z",
          "shell.execute_reply": "2023-10-30T07:10:21.022507Z"
        },
        "trusted": true,
        "id": "BE4SRbiVU6L_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, output in enumerate(greedy_output):\n",
        "    print(\"{}: {}...\".format(i, tokenizer.decode(output,\n",
        "                                                 skip_special_tokens=True)))\n",
        "    print('')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:21.025350Z",
          "iopub.execute_input": "2023-10-30T07:10:21.025695Z",
          "iopub.status.idle": "2023-10-30T07:10:21.035326Z",
          "shell.execute_reply.started": "2023-10-30T07:10:21.025666Z",
          "shell.execute_reply": "2023-10-30T07:10:21.034155Z"
        },
        "trusted": true,
        "id": "dtD6Wf0GU6L_",
        "outputId": "2ab0390a-676c-4d4f-c6c8-8a27c861df17"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "0: I am an Artificial Intelligence Developer. I am a software developer. And I'm a programmer.\n\nI'm not a computer scientist. But I do have a lot of experience in the field of Artificial intelligence. So I think that I can help you understand the challenges of AI. You can learn about the problems of artificial intelligence and how they can be solved. It's not just about solving problems. There are many other things that can go wrong. We can't just solve problems by solving them...\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "beam_output = model.generate(input_ids,\n",
        "                             max_length = 100,\n",
        "                             num_beams=5,\n",
        "                             num_return_sequences=5,\n",
        "                             no_repeat_ngram_size=2,\n",
        "                             early_stopping=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:21.036545Z",
          "iopub.execute_input": "2023-10-30T07:10:21.036841Z",
          "iopub.status.idle": "2023-10-30T07:10:28.323956Z",
          "shell.execute_reply.started": "2023-10-30T07:10:21.036816Z",
          "shell.execute_reply": "2023-10-30T07:10:28.322947Z"
        },
        "trusted": true,
        "id": "cUQhUh8qU6L_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beam_output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:28.325326Z",
          "iopub.execute_input": "2023-10-30T07:10:28.325730Z",
          "iopub.status.idle": "2023-10-30T07:10:28.336975Z",
          "shell.execute_reply.started": "2023-10-30T07:10:28.325701Z",
          "shell.execute_reply": "2023-10-30T07:10:28.336100Z"
        },
        "trusted": true,
        "id": "qfgFdRgSU6L_",
        "outputId": "9eff87b9-ea28-441f-8cfd-7f023c0701f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "tensor([[   40,   716,   281, 35941,  9345, 23836,    13,   314,   423,   587,\n          1762,   319,  9552,   329,   257,   890,   640,   290,   314,   716,\n           845,  6568,   546,   262,  2003,   286,  9552,    13,   198,   198,\n            40,   423,   257,  1256,   286,  1998,   287,   262,  2214,   286,\n         11666,  4430,    13,   554,   262,   938,  1178,   812,    11,   314,\n          1053,   587,  2950,   287,   257,  1271,   286,  1180,  4493,    11,\n          1390,   262,  2478,   286,   262,  9552,  3859,   329,  3012,   338,\n          5565,  3859,    11,   290,   262,  6282,   286,   281,  9552,    12,\n         12293,  5175,   598,   329,  4196,   338,  8969,  3859,    13,  2312,\n          4493,   423,  2957,   502,   284,   262,  7664,   326,  9552,   318],\n        [   40,   716,   281, 35941,  9345, 23836,    13,   314,   423,   587,\n          1762,   319,  9552,   329,   257,   890,   640,   290,   314,   716,\n           845,  6568,   546,   262,  2003,   286,  9552,    13,   198,   198,\n            40,   423,   257,  1256,   286,  1998,   287,   262,  2214,   286,\n         11666,  4430,    13,   554,   262,   938,  1178,   812,    11,   314,\n          1053,   587,  2950,   287,   257,  1271,   286,  1180,  4493,    11,\n          1390,   262,  2478,   286,   262,  9552,  3859,   329,  3012,   338,\n          5565,  3859,    11,   290,   262,  6282,   286,   281,  9552,    12,\n         12293,  5175,   598,   329,  4196,   338,  8969,  3859,    13,  2312,\n          4493,   423,  2957,   502,   284,  1975,   326,  9552,   318,   257],\n        [   40,   716,   281, 35941,  9345, 23836,    13,   314,   423,   587,\n          1762,   319,  9552,   329,   257,   890,   640,   290,   314,   716,\n           845,  6568,   546,   262,  2003,   286,  9552,    13,   198,   198,\n            40,   423,   257,  1256,   286,  1998,   287,   262,  2214,   286,\n         11666,  4430,    13,   554,   262,   938,  1178,   812,    11,   314,\n          1053,   587,  2950,   287,   257,  1271,   286,  1180,  4493,    11,\n          1390,   262,  2478,   286,   262,  9552,  3859,   329,  3012,   338,\n          5565,  3859,    11,   290,   262,  6282,   286,   281,  9552,    12,\n         12293,  5175,   598,   329,  4196,   338,  8969,  3859,    13,  2312,\n          4493,   423,  2957,   502,   284,  1975,   326,  9552,   481,   307],\n        [   40,   716,   281, 35941,  9345, 23836,    13,   314,   423,   587,\n          1762,   319,  9552,   329,   257,   890,   640,   290,   314,   716,\n           845,  6568,   546,   262,  2003,   286,  9552,    13,   198,   198,\n            40,   423,   257,  1256,   286,  1998,   287,   262,  2214,   286,\n         11666,  4430,    13,   554,   262,   938,  1178,   812,    11,   314,\n          1053,   587,  2950,   287,   257,  1271,   286,  1180,  4493,    11,\n          1390,   262,  2478,   286,   262,  9552,  3859,   329,  3012,   338,\n          5565,  3859,    11,   290,   262,  6282,   286,   281,  9552,    12,\n         12293,  5175,   598,   329,  4196,   338,  8969,  3859,    13,  2312,\n          4493,   423,  2957,   502,   284,  1975,   326,  9552,   318,   262],\n        [   40,   716,   281, 35941,  9345, 23836,    13,   314,   423,   587,\n          1762,   319,  9552,   329,   257,   890,   640,   290,   314,   716,\n           845,  6568,   546,   262,  2003,   286,  9552,    13,   198,   198,\n            40,   423,   257,  1256,   286,  1998,   287,   262,  2214,   286,\n         11666,  4430,    13,   554,   262,   938,  1178,   812,    11,   314,\n          1053,   587,  2950,   287,   257,  1271,   286,  1180,  4493,    11,\n          1390,   262,  2478,   286,   262,  9552,  3859,   329,  3012,   338,\n          5565,  3859,    11,   290,   262,  6282,   286,   281,  9552,    12,\n         12293,  5175,   598,   329,  4196,   338,  8969,  3859,    13,  2312,\n          4493,   423,  2957,   502,   284,  1975,   326,  9552,   460,   307]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, output in enumerate(beam_output):\n",
        "    print(\"{}: {}...\".format(i, tokenizer.decode(output,\n",
        "                                                 skip_special_tokens=True)))\n",
        "    print('')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:28.338213Z",
          "iopub.execute_input": "2023-10-30T07:10:28.338550Z",
          "iopub.status.idle": "2023-10-30T07:10:28.357773Z",
          "shell.execute_reply.started": "2023-10-30T07:10:28.338519Z",
          "shell.execute_reply": "2023-10-30T07:10:28.356814Z"
        },
        "trusted": true,
        "id": "wHxWuZRRU6L_",
        "outputId": "3ec40ea8-4756-4e6c-fc65-17be2e1e39ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "0: I am an Artificial Intelligence Developer. I have been working on AI for a long time and I am very excited about the future of AI.\n\nI have a lot of experience in the field of artificial intelligence. In the last few years, I've been involved in a number of different projects, including the development of the AI platform for Google's Android platform, and the creation of an AI-powered mobile app for Apple's iOS platform. These projects have led me to the conclusion that AI is...\n\n1: I am an Artificial Intelligence Developer. I have been working on AI for a long time and I am very excited about the future of AI.\n\nI have a lot of experience in the field of artificial intelligence. In the last few years, I've been involved in a number of different projects, including the development of the AI platform for Google's Android platform, and the creation of an AI-powered mobile app for Apple's iOS platform. These projects have led me to believe that AI is a...\n\n2: I am an Artificial Intelligence Developer. I have been working on AI for a long time and I am very excited about the future of AI.\n\nI have a lot of experience in the field of artificial intelligence. In the last few years, I've been involved in a number of different projects, including the development of the AI platform for Google's Android platform, and the creation of an AI-powered mobile app for Apple's iOS platform. These projects have led me to believe that AI will be...\n\n3: I am an Artificial Intelligence Developer. I have been working on AI for a long time and I am very excited about the future of AI.\n\nI have a lot of experience in the field of artificial intelligence. In the last few years, I've been involved in a number of different projects, including the development of the AI platform for Google's Android platform, and the creation of an AI-powered mobile app for Apple's iOS platform. These projects have led me to believe that AI is the...\n\n4: I am an Artificial Intelligence Developer. I have been working on AI for a long time and I am very excited about the future of AI.\n\nI have a lot of experience in the field of artificial intelligence. In the last few years, I've been involved in a number of different projects, including the development of the AI platform for Google's Android platform, and the creation of an AI-powered mobile app for Apple's iOS platform. These projects have led me to believe that AI can be...\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_output = model.generate(input_ids,\n",
        "                               do_sample=True,\n",
        "                               max_length=100,\n",
        "                               top_k=0,\n",
        "                               temperature=0.8)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:28.359015Z",
          "iopub.execute_input": "2023-10-30T07:10:28.359375Z",
          "iopub.status.idle": "2023-10-30T07:10:31.613355Z",
          "shell.execute_reply.started": "2023-10-30T07:10:28.359344Z",
          "shell.execute_reply": "2023-10-30T07:10:31.612531Z"
        },
        "trusted": true,
        "id": "SdpA20EBU6MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, output in enumerate(random_output):\n",
        "    print(\"{}: {}...\".format(i, tokenizer.decode(output,\n",
        "                                                 skip_special_tokens=True)))\n",
        "    print('')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:31.614773Z",
          "iopub.execute_input": "2023-10-30T07:10:31.615155Z",
          "iopub.status.idle": "2023-10-30T07:10:31.624096Z",
          "shell.execute_reply.started": "2023-10-30T07:10:31.615103Z",
          "shell.execute_reply": "2023-10-30T07:10:31.623130Z"
        },
        "trusted": true,
        "id": "SiypLZlZU6MA",
        "outputId": "e52bd1af-a355-4e23-ec76-43f789557804"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "0: I am an Artificial Intelligence Developer, who is often asked to explain his technical work to you. I go into a lot of detail about the topics and concepts of artificial intelligence in this course, and it is very easy to understand how people think and work in general. Much of the book is on deep learning, and I will cover many of the topics most people have not learned in several years. In addition to the topics covered, there are some points I experimenting with, including the idea that a computer...\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_k_output = model.generate(input_ids,\n",
        "                              do_sample=True,\n",
        "                              max_length=100,\n",
        "                              top_k=50)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:31.625641Z",
          "iopub.execute_input": "2023-10-30T07:10:31.626008Z",
          "iopub.status.idle": "2023-10-30T07:10:35.004980Z",
          "shell.execute_reply.started": "2023-10-30T07:10:31.625973Z",
          "shell.execute_reply": "2023-10-30T07:10:35.004163Z"
        },
        "trusted": true,
        "id": "nHIM0qT3U6MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, output in enumerate(top_k_output):\n",
        "    print(\"{}: {}...\".format(i, tokenizer.decode(output,\n",
        "                                                 skip_special_tokens=True)))\n",
        "    print('')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:35.006626Z",
          "iopub.execute_input": "2023-10-30T07:10:35.006983Z",
          "iopub.status.idle": "2023-10-30T07:10:35.016210Z",
          "shell.execute_reply.started": "2023-10-30T07:10:35.006948Z",
          "shell.execute_reply": "2023-10-30T07:10:35.015204Z"
        },
        "trusted": true,
        "id": "-0Y8OICMU6MA",
        "outputId": "1005fa4d-66cf-4aad-afdc-fe69db6b4301"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "0: I am an Artificial Intelligence Developer and I think that even if you're getting a lot of applications of AI in your day to day life, it is very, very difficult to make a good decision or not. The difference between good news and bad news is actually quite significant.\n\nQ. You have started a company to build a new kind of AI, for the sake of innovation, with the help of artificial intelligence. How are you planning on using AI to move forward in this direction?\n...\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_p_output = model.generate(input_ids,\n",
        "                              do_sample=True,\n",
        "                              max_length=100,\n",
        "                              top_p=0.8,\n",
        "                              top_k=0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:35.017580Z",
          "iopub.execute_input": "2023-10-30T07:10:35.018365Z",
          "iopub.status.idle": "2023-10-30T07:10:38.751151Z",
          "shell.execute_reply.started": "2023-10-30T07:10:35.018331Z",
          "shell.execute_reply": "2023-10-30T07:10:38.750342Z"
        },
        "trusted": true,
        "id": "N0i9zY3HU6MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, output in enumerate(top_p_output):\n",
        "    print(\"{}: {}...\".format(i, tokenizer.decode(output,\n",
        "                                                 skip_special_tokens=True)))\n",
        "    print('')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:38.756180Z",
          "iopub.execute_input": "2023-10-30T07:10:38.756441Z",
          "iopub.status.idle": "2023-10-30T07:10:38.765065Z",
          "shell.execute_reply.started": "2023-10-30T07:10:38.756418Z",
          "shell.execute_reply": "2023-10-30T07:10:38.764091Z"
        },
        "trusted": true,
        "id": "xecPa7MuU6MB",
        "outputId": "60651a65-4c51-4ee6-9a9e-b37d6de292fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "0: I am an Artificial Intelligence Developer who just recently joined the #IBEL leadership team at UBI. I'm able to talk about the future of AI and my thoughts on AI-driven solutions, whether you're in the fields of UI design, game design, or product development.\n\nJB: Oh my goodness. It's so nice to meet you all.\n\nJH: Thank you.\n\nJB: I love talking to you all! I want to thank you all for being...\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_k_p_outputs = model.generate(input_ids,\n",
        "                                 do_sample=True,\n",
        "                                 max_length=2*100,\n",
        "                                 top_k=50,\n",
        "                                 top_p=0.85,\n",
        "                                 num_return_sequences=5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:38.766258Z",
          "iopub.execute_input": "2023-10-30T07:10:38.766534Z",
          "iopub.status.idle": "2023-10-30T07:10:55.760736Z",
          "shell.execute_reply.started": "2023-10-30T07:10:38.766510Z",
          "shell.execute_reply": "2023-10-30T07:10:55.759881Z"
        },
        "trusted": true,
        "id": "yw_SMHISU6MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, output in enumerate(top_k_p_outputs):\n",
        "    print(\"{}: {}...\".format(i, tokenizer.decode(output,\n",
        "                                                 skip_special_tokens=True)))\n",
        "    print('')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:55.762018Z",
          "iopub.execute_input": "2023-10-30T07:10:55.762380Z",
          "iopub.status.idle": "2023-10-30T07:10:55.792246Z",
          "shell.execute_reply.started": "2023-10-30T07:10:55.762347Z",
          "shell.execute_reply": "2023-10-30T07:10:55.791242Z"
        },
        "trusted": true,
        "id": "r7YGdCzDU6MC",
        "outputId": "be314c01-bfc1-4d36-96e4-a32dc320f7d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "0: I am an Artificial Intelligence Developer with a lot of experience in creating AI applications. I have been programming for over 3 years and have worked in a lot of applications. I have taught a lot of programming languages with lots of experience and I do believe that I am the only person who could make an intelligent system that works well. I believe that there is no single solution that I can create that would be perfect for me, but I have made a number of attempts, many of them successful, but I still believe that there is only one way to accomplish this goal. I have come to the conclusion that we need to move to an AI world, where humans will be the dominant player in many fields. We need to be able to build AI systems that do not have to work in humans, and we must be able to make them work in the human world. In this post I am going to talk about what I believe can be done. I will go into the technical aspects of what I believe can...\n\n1: I am an Artificial Intelligence Developer, I work for the UK Government's Intelligence Agency, but I also work for Google, so I don't have access to all of the things you're talking about. But I know the value of that in the context of the world. I know there are so many things that are missing in the future. But the thing that's exciting is that the big picture is not that it can't be done. There are so many ways that we can move beyond the next two-year window. There is so much more that we can do. We have a long way to go. There is so much more to do and there are so many different opportunities....\n\n2: I am an Artificial Intelligence Developer at CERN. As an engineer working in a large group of AI scientists, I have many ideas for the future of the field, and I am excited to share what I have learned so far. I am particularly interested in the next generation of artificial intelligence (AI) devices: these devices will be able to take advantage of data collected from all manner of devices in order to build great machines with incredible power. I hope that the future of artificial intelligence will not be so bright for humanity.\n\nIf you like this, you can support this work by pledging a small amount of money. Thank you....\n\n3: I am an Artificial Intelligence Developer. I know how to run real time games and I'm not just a programmer. In fact, I am quite talented. I've built almost everything in game development in just about four months. I'm an experienced programmer with a proven track record of building awesome games, and this is what I want to do in the next couple of months.\n\nAs part of this process, I'm also making progress toward developing the first full-screen, single player campaign, which is just a prototype. binsvids.com\n\nAnd what's in that game?\n\nWell, as a gamer, I'm definitely looking for something different to play around with. I'm also working on a game that is almost like a full-fledged roguelike, complete with all the game mechanics. This will be the first game I ever build in the series, and the game will be made using real-time combat, so I'm trying to make a good idea...\n\n4: I am an Artificial Intelligence Developer, and I have been teaching my kids in STEM since I was 12 years old. My dream is to do what is best for their future. I am interested in teaching people how to be great. I am a realist. I believe that every person should strive to be more than just a programmer. The more they work the more they will find a purpose and their creativity will improve. I am a realist. If you want to become a good computer programmer, you have to be passionate about STEM, and the way that you work. I have taken a hard look at the world and I know it is a challenge for all of us. There is no shortage of jobs available at Microsoft. And there is more demand for STEM programming than ever before.\n\nI have started my own business on the side of the kids in high school. I have built the world's first robot lab, and I am developing the world's first mobile app for Android, for...\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "dataset_name = \"tiny_shakespeare\"\n",
        "cache_dir = \"lm_dataset/\"\n",
        "datasets = load_dataset(dataset_name, cache_dir=cache_dir)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:55.793239Z",
          "iopub.execute_input": "2023-10-30T07:10:55.793507Z",
          "iopub.status.idle": "2023-10-30T07:10:59.210044Z",
          "shell.execute_reply.started": "2023-10-30T07:10:55.793484Z",
          "shell.execute_reply": "2023-10-30T07:10:59.209287Z"
        },
        "trusted": true,
        "id": "5963j2AIU6MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:59.211428Z",
          "iopub.execute_input": "2023-10-30T07:10:59.211723Z",
          "iopub.status.idle": "2023-10-30T07:10:59.217938Z",
          "shell.execute_reply.started": "2023-10-30T07:10:59.211697Z",
          "shell.execute_reply": "2023-10-30T07:10:59.217103Z"
        },
        "trusted": true,
        "id": "IwJ_xOJxU6MC",
        "outputId": "c2574265-5a13-476d-a646-328294a93c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 28,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text'],\n        num_rows: 1\n    })\n    validation: Dataset({\n        features: ['text'],\n        num_rows: 1\n    })\n    test: Dataset({\n        features: ['text'],\n        num_rows: 1\n    })\n})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#datasets['train'][:1]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:59.219265Z",
          "iopub.execute_input": "2023-10-30T07:10:59.219554Z",
          "iopub.status.idle": "2023-10-30T07:10:59.226961Z",
          "shell.execute_reply.started": "2023-10-30T07:10:59.219530Z",
          "shell.execute_reply": "2023-10-30T07:10:59.225923Z"
        },
        "trusted": true,
        "id": "zgByLTAeU6MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = datasets[\"train\"].column_names\n",
        "text_column_name = \"text\" if \"text\" in column_names else column_names[0]\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    output = tokenizer(examples[text_column_name])\n",
        "    return output\n",
        "\n",
        "tokenized_datasets = datasets.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=column_names,\n",
        "    desc=\"Running tokenizer on dataset\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:10:59.228227Z",
          "iopub.execute_input": "2023-10-30T07:10:59.228501Z",
          "iopub.status.idle": "2023-10-30T07:11:02.602416Z",
          "shell.execute_reply.started": "2023-10-30T07:10:59.228477Z",
          "shell.execute_reply": "2023-10-30T07:11:02.601224Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "7c6487568fce4aee82d136426755f64f",
            "173d939a2df64af0859aaaf3ca722c79",
            "2343754a35bd4487995776e15684b45b"
          ]
        },
        "id": "Yk5UvFZ_U6MC",
        "outputId": "7c2c8b9c-1380-459c-e57a-fa66ff90abdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c6487568fce4aee82d136426755f64f"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Token indices sequence length is longer than the specified maximum sequence length for this model (301966 > 1024). Running this sequence through the model will result in indexing errors\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "173d939a2df64af0859aaaf3ca722c79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2343754a35bd4487995776e15684b45b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = tokenizer.model_max_length\n",
        "if block_size > 1024:\n",
        "    block_size = 1024\n",
        "\n",
        "def group_texts(examples):\n",
        "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "    total_length = (total_length // block_size) * block_size\n",
        "    result = {\n",
        "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
        "        for k, t in concatenated_examples.items()}\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result\n",
        "\n",
        "lm_datasets = tokenized_datasets.map(\n",
        "    group_texts,\n",
        "    batched=True,\n",
        "    desc=f\"Grouping texts in chunks of {block_size}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:11:02.603935Z",
          "iopub.execute_input": "2023-10-30T07:11:02.604362Z",
          "iopub.status.idle": "2023-10-30T07:11:03.334910Z",
          "shell.execute_reply.started": "2023-10-30T07:11:02.604323Z",
          "shell.execute_reply": "2023-10-30T07:11:03.333971Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "dfd8ba0a954e43948de954656c9095c7",
            "9a30a3fdc2274c24a0fc7e9f26e10cea",
            "efe06d5787ca42009b1774de3b5ac7cf"
          ]
        },
        "id": "AW8IP97lU6MD",
        "outputId": "dff8c643-e9ec-433e-9be1-3573c9f3ecad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Grouping texts in chunks of 1024:   0%|          | 0/1 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfd8ba0a954e43948de954656c9095c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Grouping texts in chunks of 1024:   0%|          | 0/1 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a30a3fdc2274c24a0fc7e9f26e10cea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Grouping texts in chunks of 1024:   0%|          | 0/1 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efe06d5787ca42009b1774de3b5ac7cf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = lm_datasets[\"train\"]\n",
        "eval_dataset = lm_datasets[\"validation\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:11:03.336243Z",
          "iopub.execute_input": "2023-10-30T07:11:03.336608Z",
          "iopub.status.idle": "2023-10-30T07:11:03.341275Z",
          "shell.execute_reply.started": "2023-10-30T07:11:03.336574Z",
          "shell.execute_reply": "2023-10-30T07:11:03.340305Z"
        },
        "trusted": true,
        "id": "Gg12ZxPkU6MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(output_dir = \"output/\",\n",
        "                                  per_device_train_batch_size=1,\n",
        "                                  num_train_epochs=50,\n",
        "                                  save_total_limit=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:11:03.342558Z",
          "iopub.execute_input": "2023-10-30T07:11:03.342911Z",
          "iopub.status.idle": "2023-10-30T07:11:03.379077Z",
          "shell.execute_reply.started": "2023-10-30T07:11:03.342878Z",
          "shell.execute_reply": "2023-10-30T07:11:03.378152Z"
        },
        "trusted": true,
        "id": "SkVUEmwpU6MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model=model,\n",
        "                  args=training_args,\n",
        "                  train_dataset=train_dataset,\n",
        "                  eval_dataset=eval_dataset,\n",
        "                  tokenizer=tokenizer,\n",
        "                  data_collator=default_data_collator)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:11:03.380438Z",
          "iopub.execute_input": "2023-10-30T07:11:03.380723Z",
          "iopub.status.idle": "2023-10-30T07:11:07.601186Z",
          "shell.execute_reply.started": "2023-10-30T07:11:03.380698Z",
          "shell.execute_reply": "2023-10-30T07:11:07.600365Z"
        },
        "trusted": true,
        "id": "3_lrTiwkU6MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_usage()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:11:12.367318Z",
          "iopub.execute_input": "2023-10-30T07:11:12.367694Z",
          "iopub.status.idle": "2023-10-30T07:11:12.384180Z",
          "shell.execute_reply.started": "2023-10-30T07:11:12.367663Z",
          "shell.execute_reply": "2023-10-30T07:11:12.383306Z"
        },
        "trusted": true,
        "id": "6ulCByu1U6MD",
        "outputId": "a6a9b398-3f24-4fcf-a186-08747371b020"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "| ID | GPU | MEM |\n------------------\n|  0 |  0% |  8% |\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:11:13.895235Z",
          "iopub.execute_input": "2023-10-30T07:11:13.895994Z",
          "iopub.status.idle": "2023-10-30T07:11:13.900966Z",
          "shell.execute_reply.started": "2023-10-30T07:11:13.895957Z",
          "shell.execute_reply": "2023-10-30T07:11:13.899835Z"
        },
        "trusted": true,
        "id": "R4ottxvaU6MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T07:11:23.846820Z",
          "iopub.execute_input": "2023-10-30T07:11:23.847248Z",
          "iopub.status.idle": "2023-10-30T08:05:57.627428Z",
          "shell.execute_reply.started": "2023-10-30T07:11:23.847210Z",
          "shell.execute_reply": "2023-10-30T08:05:57.626338Z"
        },
        "trusted": true,
        "id": "6aODylh8U6MD",
        "outputId": "5a032fa6-3eb7-4497-f45a-dc5ca0362735"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "  \n"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "wandb version 0.15.12 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.15.9"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20231030_071134-h33ttgh5</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ilhnsevval/huggingface/runs/h33ttgh5' target=\"_blank\">spooky-ghost-17</a></strong> to <a href='https://wandb.ai/ilhnsevval/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ilhnsevval/huggingface' target=\"_blank\">https://wandb.ai/ilhnsevval/huggingface</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ilhnsevval/huggingface/runs/h33ttgh5' target=\"_blank\">https://wandb.ai/ilhnsevval/huggingface/runs/h33ttgh5</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='14700' max='14700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [14700/14700 53:49, Epoch 50/50]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>3.486100</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>3.163000</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>2.946800</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>2.732600</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>2.543700</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>2.380400</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>2.204300</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>2.047900</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>1.911300</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>1.786800</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>1.654500</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>1.546500</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>1.446300</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>1.359800</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>1.266700</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>1.203700</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>1.140000</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>1.064200</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>1.020500</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.974000</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>0.925200</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>0.882500</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>0.859600</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>0.822100</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>0.809100</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>0.776200</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>0.767000</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>0.750100</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>0.745500</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()\n",
        "\n",
        "metrics = train_result.metrics\n",
        "trainer.log_metrics(\"train\", metrics)\n",
        "trainer.save_metrics(\"train\", metrics)\n",
        "\n",
        "trainer.save_state()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T08:06:06.780705Z",
          "iopub.execute_input": "2023-10-30T08:06:06.781199Z",
          "iopub.status.idle": "2023-10-30T08:06:07.865689Z",
          "shell.execute_reply.started": "2023-10-30T08:06:06.781153Z",
          "shell.execute_reply": "2023-10-30T08:06:07.864751Z"
        },
        "trusted": true,
        "id": "Ayer2TkIU6ME",
        "outputId": "a33d9e61-1bd1-4ca1-bfe6-c64c482c7689"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "***** train metrics *****\n  epoch                    =       50.0\n  total_flos               =  7154406GF\n  train_loss               =      1.548\n  train_runtime            = 0:54:33.49\n  train_samples_per_second =      4.491\n  train_steps_per_second   =      4.491\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(2)\n",
        "\n",
        "ids = tokenizer.encode('One does not simply walk into',\n",
        "                       return_tensors='pt').cuda()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T08:06:19.378955Z",
          "iopub.execute_input": "2023-10-30T08:06:19.379884Z",
          "iopub.status.idle": "2023-10-30T08:06:19.387079Z",
          "shell.execute_reply.started": "2023-10-30T08:06:19.379850Z",
          "shell.execute_reply": "2023-10-30T08:06:19.386097Z"
        },
        "trusted": true,
        "id": "4M9_nhCGU6ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "greedy_output = model.generate(ids,\n",
        "                               max_length=100,\n",
        "                               no_repeat_ngram_size=2)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ypF3SPwvU6ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, output in enumerate(greedy_output):\n",
        "    print(\"{}: {}...\".format(i, tokenizer.decode(output,\n",
        "                                                 skip_special_tokens=True)))\n",
        "    print('')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T08:06:36.547980Z",
          "iopub.execute_input": "2023-10-30T08:06:36.548347Z",
          "iopub.status.idle": "2023-10-30T08:06:36.561251Z",
          "shell.execute_reply.started": "2023-10-30T08:06:36.548318Z",
          "shell.execute_reply": "2023-10-30T08:06:36.559968Z"
        },
        "trusted": true,
        "id": "kzCUEfdmU6ME",
        "outputId": "73473990-96ff-4070-800e-0c279be4e74c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "0: One does not simply walk into a room and yields up his or her body\nTo such as have no more in common with him;\nBut in one respect he differs from all others; and\nFor one thing, he hath in himself a nature unlike\nany in nature, and in being thus most\nbrave, to break from him.\n\nLUCIO:\nThis is a brave fellow; for he is one\nThat will, in a word, do more than one thousand...\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "beam_output = model.generate(ids,\n",
        "                             max_length = 100,\n",
        "                             num_beams=5,\n",
        "                             num_return_sequences=5,\n",
        "                             no_repeat_ngram_size=2,\n",
        "                             early_stopping=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T08:06:43.118661Z",
          "iopub.execute_input": "2023-10-30T08:06:43.119683Z",
          "iopub.status.idle": "2023-10-30T08:06:44.491530Z",
          "shell.execute_reply.started": "2023-10-30T08:06:43.119645Z",
          "shell.execute_reply": "2023-10-30T08:06:44.490366Z"
        },
        "trusted": true,
        "id": "thMM-U-aU6ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, output in enumerate(beam_output):\n",
        "    print(\"{}: {}...\".format(i, tokenizer.decode(output,\n",
        "                                                 skip_special_tokens=True)))\n",
        "    print('')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T08:06:46.525180Z",
          "iopub.execute_input": "2023-10-30T08:06:46.525996Z",
          "iopub.status.idle": "2023-10-30T08:06:46.551734Z",
          "shell.execute_reply.started": "2023-10-30T08:06:46.525963Z",
          "shell.execute_reply": "2023-10-30T08:06:46.550552Z"
        },
        "trusted": true,
        "id": "J2_1syYNU6ME",
        "outputId": "4bcc5f47-cae0-4fe2-fc2d-295e0fe551f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "0: One does not simply walk into a man's bosom and take his clothes\nfrom him; for I have seen such a thing.\n\nLADY ANNE:\nO Warwick, thou art the first that ever didst bend\nThat wronged thyself in the view of others!\nThe army of the queen am I arm'd against;\nAnd I, against thy back, will turn the diadem\nOn thy head, and burn the principal of thy pride\nWith the...\n\n1: One does not simply walk into a man's bosom and take his clothes\nfrom him; for I have seen such a thing.\n\nLADY ANNE:\nO Warwick, thou art the first that ever didst bend\nThat wronged thyself in the view of others!\nThe army of the queen am I arm'd against;\nAnd I, against thy back, will turn the diadem\nOn thy head, and burn the principal of thy pride\nWith that...\n\n2: One does not simply walk into a man's bosom and take his clothes\nfrom him; for I have seen such a thing.\n\nLADY ANNE:\nO Warwick, thou art the first that ever didst bend\nThat wronged thyself in the view of others!\nThe army of the queen am I arm'd against;\nAnd I, against thy back, will turn the diadem\nOn thy foes; till then I'll kiss their blood,\nAs...\n\n3: One does not simply walk into a man's bosom and take his clothes\nfrom him; for I have seen such a thing.\n\nLADY ANNE:\nO Warwick, thou art the first that ever didst bend\nThat wronged thyself in the view of others!\nThe army of the queen am I arm'd against;\nAnd I, against thy back, will turn the diadem\nOn thy head, and burn the principal of thy pride\nTill...\n\n4: One does not simply walk into a man's bosom and take his clothes\nfrom him; for I have seen such a thing.\n\nLADY ANNE:\nO Warwick, thou art the first that ever didst bend\nThat wronged thyself in the view of others!\nThe army of the queen am I arm'd against;\nAnd I, against thy back, will turn the diadem\nOn thy head, and burn the principal of thy pride\nIn vain...\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_output = model.generate(ids,\n",
        "                               do_sample=True,\n",
        "                               max_length=100,\n",
        "                               top_k=0,\n",
        "                               temperature=0.8)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T08:07:02.114390Z",
          "iopub.execute_input": "2023-10-30T08:07:02.115060Z",
          "iopub.status.idle": "2023-10-30T08:07:03.259000Z",
          "shell.execute_reply.started": "2023-10-30T08:07:02.115026Z",
          "shell.execute_reply": "2023-10-30T08:07:03.257976Z"
        },
        "trusted": true,
        "id": "YJNyjOxmU6ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, output in enumerate(random_output):\n",
        "    print(\"{}: {}...\".format(i, tokenizer.decode(output,\n",
        "                                                 skip_special_tokens=True)))\n",
        "    print('')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T08:07:03.260704Z",
          "iopub.execute_input": "2023-10-30T08:07:03.260993Z",
          "iopub.status.idle": "2023-10-30T08:07:03.271743Z",
          "shell.execute_reply.started": "2023-10-30T08:07:03.260967Z",
          "shell.execute_reply": "2023-10-30T08:07:03.270674Z"
        },
        "trusted": true,
        "id": "jdiNkLPHU6MF",
        "outputId": "cbb78645-9f0d-43b5-edc6-e6ddfffde2ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "0: One does not simply walk into a man's mouth and speak;\nFor I have heard some of these spoken. Thou hast undone thyself.\n\nROMEO:\nThou detestable traitor, I have seen thy face.\n\nBENVOLIO:\nO, make me happy by having him.\n\nMERCUTIO:\nAnd happy too, is it so: a woman is wont to chide.\n\nROMEO:\nHe chides for his...\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_k_output = model.generate(ids,\n",
        "                              do_sample=True,\n",
        "                              max_length=100,\n",
        "                              top_k=50)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T08:07:06.940859Z",
          "iopub.execute_input": "2023-10-30T08:07:06.941257Z",
          "iopub.status.idle": "2023-10-30T08:07:08.079007Z",
          "shell.execute_reply.started": "2023-10-30T08:07:06.941225Z",
          "shell.execute_reply": "2023-10-30T08:07:08.077946Z"
        },
        "trusted": true,
        "id": "79weqOjvU6MF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, output in enumerate(top_k_output):\n",
        "    print(\"{}: {}...\".format(i, tokenizer.decode(output,\n",
        "                                                 skip_special_tokens=True)))\n",
        "    print('')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T08:07:09.995348Z",
          "iopub.execute_input": "2023-10-30T08:07:09.995763Z",
          "iopub.status.idle": "2023-10-30T08:07:10.009788Z",
          "shell.execute_reply.started": "2023-10-30T08:07:09.995728Z",
          "shell.execute_reply": "2023-10-30T08:07:10.008564Z"
        },
        "trusted": true,
        "id": "qH4QpB6dU6MF",
        "outputId": "15abc681-477d-4bd9-c9d9-41ed4a6906b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "0: One does not simply walk into this world;\nAnd that the naked traveller be king,\nHis acts of violence transported to the end;\nYet, in this world he is king; and I, his wife,\nCan no longer say 'I love thee'\nHis warlike father advised him to, and I, his wife,\nWere angels and nature no better pleased:\nFor why, 'tis my husband's will,\nAnd I, his wife, should that be so...\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_p_output = model.generate(ids,\n",
        "                              do_sample=True,\n",
        "                              max_length=100,\n",
        "                              top_p=0.8,\n",
        "                              top_k=0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T08:07:14.709372Z",
          "iopub.execute_input": "2023-10-30T08:07:14.709748Z",
          "iopub.status.idle": "2023-10-30T08:07:15.861352Z",
          "shell.execute_reply.started": "2023-10-30T08:07:14.709720Z",
          "shell.execute_reply": "2023-10-30T08:07:15.860210Z"
        },
        "trusted": true,
        "id": "mT0npgkOU6MF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, output in enumerate(top_p_output):\n",
        "    print(\"{}: {}...\".format(i, tokenizer.decode(output,\n",
        "                                                 skip_special_tokens=True)))\n",
        "    print('')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T08:07:18.038031Z",
          "iopub.execute_input": "2023-10-30T08:07:18.039087Z",
          "iopub.status.idle": "2023-10-30T08:07:18.051710Z",
          "shell.execute_reply.started": "2023-10-30T08:07:18.039048Z",
          "shell.execute_reply": "2023-10-30T08:07:18.050655Z"
        },
        "trusted": true,
        "id": "WSHXbwqVU6MF",
        "outputId": "5cf76528-07b2-447a-b235-ec5756b1d22f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "0: One does not simply walk into the mind of the dull;\nAnd yields too much to the common feeling.\n\nSecond Murderer:\nWhat rages here in this cell?\n\nCLARENCE:\nLet black magic apprehend\nThis murderous wretch: he is come to know\nHis evil done, and by that knowledge apprehends\nThe evil done.\n\nThird Murderer:\nWhat rages here in this cell?\n\nCLARENCE:\nThat he choose...\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_k_p_outputs = model.generate(ids,\n",
        "                                 do_sample=True,\n",
        "                                 max_length=2*100,\n",
        "                                 top_k=50,\n",
        "                                 top_p=0.85,\n",
        "                                 num_return_sequences=5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T08:07:21.787062Z",
          "iopub.execute_input": "2023-10-30T08:07:21.787469Z",
          "iopub.status.idle": "2023-10-30T08:07:25.101351Z",
          "shell.execute_reply.started": "2023-10-30T08:07:21.787438Z",
          "shell.execute_reply": "2023-10-30T08:07:25.100342Z"
        },
        "trusted": true,
        "id": "XeC5EDvzU6MF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, output in enumerate(top_k_p_outputs):\n",
        "    print(\"{}: {}...\".format(i, tokenizer.decode(output,\n",
        "                                                 skip_special_tokens=True)))\n",
        "    print('')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T08:07:25.102906Z",
          "iopub.execute_input": "2023-10-30T08:07:25.103228Z",
          "iopub.status.idle": "2023-10-30T08:07:25.140635Z",
          "shell.execute_reply.started": "2023-10-30T08:07:25.103201Z",
          "shell.execute_reply": "2023-10-30T08:07:25.139684Z"
        },
        "trusted": true,
        "id": "TYcVW1XZU6MF",
        "outputId": "0e4c96cd-1d90-498d-f572-60aedf285a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "0: One does not simply walk into the world;\nOne at a time, some one at a time,\nCould within a mile encompass all the earth,\nAnd nothing can be more than the farthest world,\nWithin whose vastness all your body is,\nWhen you are cold.\n\nFLORIZEL:\nSo had you never been cold;\nBut now you have, since you can no more but think it,\nCold does encompass your thinking;\nAnd cold will cloud your thought;\nSince you cannot think it so, do not take\nYour apprehension with your apprehension.\n\nLEONTES:\nIt is a charge he makes against my better nature,\nBecause I abhor his rude delights. It is spoke so,\nMore than with thunder or with wind; so goes:\nI am no meteor; yet meteor I can behold,\nLords circling in the clouds, that roused up their fury,\nTo dash down and throw their...\n\n1: One does not simply walk into a man's bosom;\nHe, in aught, may move or move; a naked man by his garments,\nIs not naked in the sense of apparel.\nWhat he does see, he humbles him with precept;\nBut whether his folly or what contempt\nHis sceptre doth nod in reverence,\nFor ne'er was Henry beard in the view of\nA world of spiders but that he\nCan slide his limbs about like a net,\nWere index by nature to the laws\nOf anatomy; nay, all his actions are written\nIn inscriptions and epitaphs: but nay,\nHis greatest of inventions is that he\nCan turn a simple glass into an\nAn embossed map, turn a dial, turn a complex\ninto a list, add a title, set up an instrument,\nAnd with his simple act write\n'Where Julius Caesar stands, you shall have freedom:'\nHe...\n\n2: One does not simply walk into a man's heart\nAnd there shares his remorse and all mischance;\nNor, by his subtle flight and utterance, shows true descent,\nNor being pluck'd for a horse, flees past the burthen;\nNor, with the base and stern steed of his foot,\nSights or o'erpower his horse, whether it be deer or lamb,\nOr any thing of him that way;\nAnd yet he is never hit with a malay.\nCome, let us go on with the story:\nNowhere in this pack my friend lies;\nThis fellow must one at a blow of twenty must I.\nWhat must I do before I do?\n\nBENVOLIO:\nPart I as a Volscesman,\nTo give my master leave and go to Burglar.\nBut wherefore will he come?\n\nMERCUTIO:\nI'll follow him th...\n\n3: One does not simply walk into a buyer's shop and sell what he wants\nBut, when he opens, puts what is in't\nAnd from the drawer under his nose, straight and at end\nOf what he would have from the unsold, what he would lose\nBy giving away what he already has.\nThis law of partial charity will rob my very soul;\nAnd give fear unto my followers that might follow\nThis downright pernicious law!\nMark, how I scorn at the sight of this unbraided man\nThat would make good my friend, and turn the law on me\nBy throwing at it, as in so cruel\nLaw, what he hath done wrong: 'twas my dishonour,\nTo show it by my own face that he did all\nFrom my need do so.\nMark, good brother, how I scorn at the sight of\nthis unkindness, as being of manhood.\n\nLADY CAPULE...\n\n4: One does not simply walk into a room and give out his name;\n'Tis not the will of God, but the will of man\nThat he himself will retail at in the people's face;\n'Tis the will of man that will in a little butcher's\nservant knife pluck all their fat and stones.\n\nISABELLA:\nButchers have no will to do unto the will of man;\nThey must show the people their own swords and clubs.\n\nANGELO:\nIs this the way to reach the people's will?\n\nISABELLA:\nMates, they whom we should inform ourself,\nHave but little strength of will to do:\nWithin your Authority there are but few.\n\nMARIANA:\nAnd when will you then have a will with your wife and daughter?\n\nISABELLA:\nBy the grace of God she and her father;\nFor both...\n\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}